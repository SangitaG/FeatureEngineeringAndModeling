{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read gridsearched models selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split   \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report,precision_recall_curve,confusion_matrix \n",
    "from sklearn.metrics import (precision_score,accuracy_score,roc_auc_score,roc_curve, \n",
    "                             precision_recall_curve,recall_score,make_scorer,auc) \n",
    "from scipy.stats import boxcox, skew\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Read_pickled_madelon_Datasets(object):\n",
    "   \n",
    "    # Initializing object.\n",
    "    def __init__(self):\n",
    "       \n",
    "        # Read pickled data from NB1.\n",
    "        self.data_dir = '../dataNB1/'    \n",
    "\n",
    "        self.read_all_data_from_files()\n",
    "        \n",
    "    def read_all_data_from_files(self):\n",
    "        self.X_train_data_df_1 = pd.read_pickle(self.data_dir +'X_train_data_df_1.p')\n",
    "        self.X_train_data_df_2 = pd.read_pickle(self.data_dir +'X_train_data_df_2.p')\n",
    "        self.X_train_data_df_3 = pd.read_pickle(self.data_dir +'X_train_data_df_3.p')\n",
    "\n",
    "        self.X_valid_data_df = pd.read_pickle(self.data_dir +'X_valid_data_df.p')\n",
    "        \n",
    "        self.y_train_data_1 = pd.read_pickle(self.data_dir + 'y_train_data_1.p')\n",
    "        self.y_train_data_2 = pd.read_pickle(self.data_dir + 'y_train_data_2.p')\n",
    "        self.y_train_data_3 = pd.read_pickle(self.data_dir + 'y_train_data_3.p')\n",
    "        \n",
    "        self.y_valid_data = pd.read_pickle(self.data_dir + 'y_valid_data.p')\n",
    "        \n",
    "    def get_X_train_data_sets(self):\n",
    "        return(self.X_train_data_df_1, self.X_train_data_df_2, self.X_train_data_df_3)\n",
    "    \n",
    "    def get_X_valid_data(self):\n",
    "        return(self.X_valid_data_df)\n",
    "    \n",
    "\n",
    "    def get_X_test_data(self):\n",
    "        return(self.X_test_data_df)\n",
    "       \n",
    "    def get_y_train_data(self):        \n",
    "        # y data should be a 1D array of labels. It is now read as a dataframe of 1 column with each\n",
    "        # element as a list of one int.  We want it to be just an int not a list.\n",
    "        self.y_train_data_1 = np.array([val[0] for val in self.y_train_data_1.values])\n",
    "        self.y_train_data_2 = np.array([val[0] for val in self.y_train_data_2.values])\n",
    "        self.y_train_data_3 = np.array([val[0] for val in self.y_train_data_3.values])\n",
    "        \n",
    "        return(self.y_train_data_1, self.y_train_data_2, self.y_train_data_3)\n",
    "\n",
    "    def get_y_valid_data(self):        \n",
    "        # y data should be a 1D array of labels. It is now read as a dataframe of 1 column with each\n",
    "        # element as a list of one int.  We want it to be just an int not a list.\n",
    "        self.y_valid_data = np.array([val[0] for val in self.y_valid_data.values])\n",
    "\n",
    "        return(self.y_valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in DB Madelon Data. For this notebook we only need the X and y train data.\n",
    "read_data = Read_pickled_madelon_Datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X train data.\n",
    "X_train_data_df_1, X_train_data_df_2, X_train_data_df_3 = \\\n",
    "                                                        read_data.get_X_train_data_sets()\n",
    "# y train data.\n",
    "y_train_1, y_train_2, y_train_3 = read_data.get_y_train_data()\n",
    "\n",
    "# X train datasets in a list.\n",
    "X_train_subsets = [X_train_data_df_1, X_train_data_df_2, X_train_data_df_3]\n",
    "\n",
    "# y train datasets in a list.\n",
    "y_train_subsets = [y_train_1, y_train_2, y_train_3]\n",
    "\n",
    "# Read pickled X validate data.\n",
    "X_validate = read_data.get_X_valid_data()\n",
    "\n",
    "# Read pickled y validate data.\n",
    "y_validate = read_data.get_y_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read pickled data subsets with only the selected features.\n",
    "\n",
    "X_train_sel_feats_subsets_df=[]\n",
    "X_train_sel_feats_subsets_df.append(pd.read_pickle('../dataNB3/X_train_sel_feats_subsets_df1.p'))\n",
    "X_train_sel_feats_subsets_df.append(pd.read_pickle('../dataNB3/X_train_sel_feats_subsets_df2.p'))\n",
    "X_train_sel_feats_subsets_df.append(pd.read_pickle('../dataNB3/X_train_sel_feats_subsets_df3.p'))\n",
    "\n",
    "Xtest_sel_feats = pd.read_pickle('../dataNB3/X_test_sel_feats_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_results_df = pd.read_pickle('../dataNB3/FinalModels_GOOD_FINAL.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>sc_tr_acc_score</th>\n",
       "      <th>sc_tst_acc_score</th>\n",
       "      <th>sc_precision</th>\n",
       "      <th>sc_recall</th>\n",
       "      <th>pipe_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Set_1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591362</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Set_1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Set_1</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.767372</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Set_1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.905844</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Set_2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591362</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Set_2</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Set_2</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.773414</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Set_2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.905844</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Set_3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591362</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Set_3</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Set_3</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.771341</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Set_3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.905844</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>Pipeline(steps=[('standardscaler', StandardSca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset               model  sc_tr_acc_score  sc_tst_acc_score  \\\n",
       "0    Set_1  LogisticRegression            0.614          0.591667   \n",
       "1    Set_1                 SVC            0.987          0.915000   \n",
       "2    Set_1        DecisionTree            0.870          0.795000   \n",
       "3    Set_1                 KNN            1.000          0.916667   \n",
       "4    Set_2  LogisticRegression            0.614          0.591667   \n",
       "5    Set_2                 SVC            0.987          0.915000   \n",
       "6    Set_2        DecisionTree            0.870          0.801667   \n",
       "7    Set_2                 KNN            1.000          0.916667   \n",
       "8    Set_3  LogisticRegression            0.614          0.591667   \n",
       "9    Set_3                 SVC            0.987          0.915000   \n",
       "10   Set_3        DecisionTree            0.870          0.796667   \n",
       "11   Set_3                 KNN            1.000          0.916667   \n",
       "\n",
       "    sc_precision  sc_recall                                        pipe_object  \n",
       "0       0.591362   0.593333  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "1       0.902913   0.930000  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "2       0.767372   0.846667  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "3       0.905844   0.930000  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "4       0.591362   0.593333  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "5       0.902913   0.930000  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "6       0.773414   0.853333  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "7       0.905844   0.930000  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "8       0.591362   0.593333  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "9       0.902913   0.930000  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "10      0.771341   0.843333  Pipeline(steps=[('standardscaler', StandardSca...  \n",
       "11      0.905844   0.930000  Pipeline(steps=[('standardscaler', StandardSca...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gridsearch results from Notebook3. The gridsearch was performed on the entire train set UCI data \n",
    "# of 2000 rows. The test data used, was UCI's X valid and y valida data.\n",
    "\n",
    "model_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final Best models retrieved from gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_df.pipe_object[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_df.pipe_object[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features selected from feauture selection methods in NB2 and NB3. (20 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 28,  48,  64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433,\n",
       "            442, 451, 453, 455, 472, 475, 493],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_selected = X_train_sel_feats_subsets_df[0].columns\n",
    "features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the entire pickled UCI training dataset.\n",
    "X_train_data_df = pd.read_pickle('../dataNB1/' +'X_train_data_df.p')\n",
    "y_train_data_df = pd.read_pickle('../dataNB1/' +'y_train_data.p')\n",
    "y_train_data_arr = np.array([val[0] for val in y_train_data_df.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all of UCI's train data, subsetted by the selected features.\n",
    "Xtrain = X_train_data_df[features_selected]\n",
    "\n",
    "# y train will be y data for subset 2 and 3 appended together.\n",
    "ytrain = y_train_data_arr\n",
    "\n",
    "# X test and y test are pickled data that I set aside for this final step. They are 1500 rows.\n",
    "Xtest = X_validate[features_selected]\n",
    "\n",
    "ytest = y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 20), (2000,), (600, 20), (600,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28</th>\n",
       "      <th>48</th>\n",
       "      <th>64</th>\n",
       "      <th>105</th>\n",
       "      <th>128</th>\n",
       "      <th>153</th>\n",
       "      <th>241</th>\n",
       "      <th>281</th>\n",
       "      <th>318</th>\n",
       "      <th>336</th>\n",
       "      <th>338</th>\n",
       "      <th>378</th>\n",
       "      <th>433</th>\n",
       "      <th>442</th>\n",
       "      <th>451</th>\n",
       "      <th>453</th>\n",
       "      <th>455</th>\n",
       "      <th>472</th>\n",
       "      <th>475</th>\n",
       "      <th>493</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459</td>\n",
       "      <td>440</td>\n",
       "      <td>648</td>\n",
       "      <td>181</td>\n",
       "      <td>452</td>\n",
       "      <td>575</td>\n",
       "      <td>434</td>\n",
       "      <td>517</td>\n",
       "      <td>414</td>\n",
       "      <td>658</td>\n",
       "      <td>628</td>\n",
       "      <td>419</td>\n",
       "      <td>533</td>\n",
       "      <td>568</td>\n",
       "      <td>463</td>\n",
       "      <td>471</td>\n",
       "      <td>630</td>\n",
       "      <td>515</td>\n",
       "      <td>401</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>475</td>\n",
       "      <td>499</td>\n",
       "      <td>488</td>\n",
       "      <td>431</td>\n",
       "      <td>473</td>\n",
       "      <td>404</td>\n",
       "      <td>551</td>\n",
       "      <td>435</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>528</td>\n",
       "      <td>526</td>\n",
       "      <td>442</td>\n",
       "      <td>463</td>\n",
       "      <td>474</td>\n",
       "      <td>311</td>\n",
       "      <td>582</td>\n",
       "      <td>465</td>\n",
       "      <td>549</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>491</td>\n",
       "      <td>460</td>\n",
       "      <td>485</td>\n",
       "      <td>593</td>\n",
       "      <td>487</td>\n",
       "      <td>585</td>\n",
       "      <td>474</td>\n",
       "      <td>535</td>\n",
       "      <td>506</td>\n",
       "      <td>465</td>\n",
       "      <td>431</td>\n",
       "      <td>464</td>\n",
       "      <td>569</td>\n",
       "      <td>503</td>\n",
       "      <td>481</td>\n",
       "      <td>606</td>\n",
       "      <td>424</td>\n",
       "      <td>485</td>\n",
       "      <td>454</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472</td>\n",
       "      <td>529</td>\n",
       "      <td>415</td>\n",
       "      <td>698</td>\n",
       "      <td>493</td>\n",
       "      <td>591</td>\n",
       "      <td>569</td>\n",
       "      <td>526</td>\n",
       "      <td>458</td>\n",
       "      <td>398</td>\n",
       "      <td>377</td>\n",
       "      <td>553</td>\n",
       "      <td>565</td>\n",
       "      <td>447</td>\n",
       "      <td>472</td>\n",
       "      <td>545</td>\n",
       "      <td>456</td>\n",
       "      <td>457</td>\n",
       "      <td>602</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>472</td>\n",
       "      <td>429</td>\n",
       "      <td>387</td>\n",
       "      <td>451</td>\n",
       "      <td>475</td>\n",
       "      <td>448</td>\n",
       "      <td>538</td>\n",
       "      <td>456</td>\n",
       "      <td>462</td>\n",
       "      <td>385</td>\n",
       "      <td>509</td>\n",
       "      <td>424</td>\n",
       "      <td>462</td>\n",
       "      <td>536</td>\n",
       "      <td>472</td>\n",
       "      <td>426</td>\n",
       "      <td>465</td>\n",
       "      <td>500</td>\n",
       "      <td>560</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   28   48   64   105  128  153  241  281  318  336  338  378  433  442  451  \\\n",
       "0  459  440  648  181  452  575  434  517  414  658  628  419  533  568  463   \n",
       "1  475  499  488  431  473  404  551  435  469  469  528  526  442  463  474   \n",
       "2  491  460  485  593  487  585  474  535  506  465  431  464  569  503  481   \n",
       "3  472  529  415  698  493  591  569  526  458  398  377  553  565  447  472   \n",
       "4  472  429  387  451  475  448  538  456  462  385  509  424  462  536  472   \n",
       "\n",
       "   453  455  472  475  493  \n",
       "0  471  630  515  401  485  \n",
       "1  311  582  465  549  338  \n",
       "2  606  424  485  454  650  \n",
       "3  545  456  457  602  572  \n",
       "4  426  465  500  560  435  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28</th>\n",
       "      <th>48</th>\n",
       "      <th>64</th>\n",
       "      <th>105</th>\n",
       "      <th>128</th>\n",
       "      <th>153</th>\n",
       "      <th>241</th>\n",
       "      <th>281</th>\n",
       "      <th>318</th>\n",
       "      <th>336</th>\n",
       "      <th>338</th>\n",
       "      <th>378</th>\n",
       "      <th>433</th>\n",
       "      <th>442</th>\n",
       "      <th>451</th>\n",
       "      <th>453</th>\n",
       "      <th>455</th>\n",
       "      <th>472</th>\n",
       "      <th>475</th>\n",
       "      <th>493</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>436</td>\n",
       "      <td>450</td>\n",
       "      <td>420</td>\n",
       "      <td>472</td>\n",
       "      <td>409</td>\n",
       "      <td>541</td>\n",
       "      <td>432</td>\n",
       "      <td>513</td>\n",
       "      <td>418</td>\n",
       "      <td>523</td>\n",
       "      <td>423</td>\n",
       "      <td>427</td>\n",
       "      <td>444</td>\n",
       "      <td>486</td>\n",
       "      <td>300</td>\n",
       "      <td>548</td>\n",
       "      <td>454</td>\n",
       "      <td>538</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>491</td>\n",
       "      <td>544</td>\n",
       "      <td>629</td>\n",
       "      <td>541</td>\n",
       "      <td>480</td>\n",
       "      <td>567</td>\n",
       "      <td>456</td>\n",
       "      <td>519</td>\n",
       "      <td>522</td>\n",
       "      <td>626</td>\n",
       "      <td>484</td>\n",
       "      <td>580</td>\n",
       "      <td>559</td>\n",
       "      <td>414</td>\n",
       "      <td>484</td>\n",
       "      <td>523</td>\n",
       "      <td>547</td>\n",
       "      <td>439</td>\n",
       "      <td>429</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>437</td>\n",
       "      <td>426</td>\n",
       "      <td>500</td>\n",
       "      <td>480</td>\n",
       "      <td>485</td>\n",
       "      <td>517</td>\n",
       "      <td>471</td>\n",
       "      <td>482</td>\n",
       "      <td>383</td>\n",
       "      <td>485</td>\n",
       "      <td>432</td>\n",
       "      <td>485</td>\n",
       "      <td>526</td>\n",
       "      <td>477</td>\n",
       "      <td>479</td>\n",
       "      <td>457</td>\n",
       "      <td>494</td>\n",
       "      <td>517</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472</td>\n",
       "      <td>447</td>\n",
       "      <td>574</td>\n",
       "      <td>314</td>\n",
       "      <td>463</td>\n",
       "      <td>405</td>\n",
       "      <td>425</td>\n",
       "      <td>426</td>\n",
       "      <td>458</td>\n",
       "      <td>560</td>\n",
       "      <td>700</td>\n",
       "      <td>443</td>\n",
       "      <td>427</td>\n",
       "      <td>649</td>\n",
       "      <td>472</td>\n",
       "      <td>453</td>\n",
       "      <td>525</td>\n",
       "      <td>540</td>\n",
       "      <td>386</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>501</td>\n",
       "      <td>499</td>\n",
       "      <td>395</td>\n",
       "      <td>471</td>\n",
       "      <td>417</td>\n",
       "      <td>537</td>\n",
       "      <td>434</td>\n",
       "      <td>451</td>\n",
       "      <td>483</td>\n",
       "      <td>609</td>\n",
       "      <td>517</td>\n",
       "      <td>448</td>\n",
       "      <td>518</td>\n",
       "      <td>470</td>\n",
       "      <td>368</td>\n",
       "      <td>570</td>\n",
       "      <td>487</td>\n",
       "      <td>527</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   28   48   64   105  128  153  241  281  318  336  338  378  433  442  451  \\\n",
       "0  490  436  450  420  472  409  541  432  513  418  523  423  427  444  486   \n",
       "1  491  544  629  541  480  567  456  519  522  626  484  580  559  414  484   \n",
       "2  479  437  426  500  480  485  517  471  482  383  485  432  485  526  477   \n",
       "3  472  447  574  314  463  405  425  426  458  560  700  443  427  649  472   \n",
       "4  469  501  499  395  471  417  537  434  451  483  609  517  448  518  470   \n",
       "\n",
       "   453  455  472  475  493  \n",
       "0  300  548  454  538  259  \n",
       "1  523  547  439  429  534  \n",
       "2  479  457  494  517  495  \n",
       "3  453  525  540  386  463  \n",
       "4  368  570  487  527  343  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1,  1,  1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model_results = []\n",
    "target_names=['class 0', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* KNN ********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.92      0.90      0.91       300\n",
      "    class 1       0.90      0.93      0.91       300\n",
      "\n",
      "avg / total       0.91      0.91      0.91       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tst_set in tqdm(range(1)):                                     \n",
    "\n",
    "    # FINAL MODEL: KNN pipes.\n",
    "    KNN_scaled_pipe = make_pipeline(StandardScaler(), \n",
    "                                    PCA(),\n",
    "                                    KNeighborsClassifier(n_neighbors = 5, weights='uniform'))\n",
    "                                               \n",
    "    # Fit and score pipeline.\n",
    "    KNN_scaled_pipe.fit(Xtrain, ytrain) \n",
    "    \n",
    "    # Mean accuracy score is returned.\n",
    "    train_score = KNN_scaled_pipe.score(Xtrain,ytrain)\n",
    "    test_score = KNN_scaled_pipe.score(Xtest,ytest)  \n",
    "    y_pred = KNN_scaled_pipe.predict(Xtest)\n",
    "    \n",
    "    # Calculate precision and recall.   \n",
    "    recall = recall_score(ytest, y_pred)\n",
    "    precision = precision_score(ytest, y_pred)\n",
    "    \n",
    "    output = {'train_score': train_score, \n",
    "              'test_score' : test_score, \n",
    "              'recall'     : recall, \n",
    "              'precision'  : precision,\n",
    "              'model_name' : 'KNN'}\n",
    "    \n",
    "    final_model_results.append(output)\n",
    "    \n",
    "    #classification reports. \n",
    "    class_report_KNN_str = classification_report(ytest, y_pred, target_names=target_names)       \n",
    "    print(\"********* KNN ********\\n\\n\", class_report_KNN_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.902597</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.9365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  precision    recall  test_score  train_score\n",
       "0        KNN   0.902597  0.926667    0.913333       0.9365"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
